{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/vdb/abenechehab/conda_envs/adapters2/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/mnt/vdb/abenechehab/conda_envs/adapters2/lib/python3.11/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/mnt/vdb/abenechehab/conda_envs/adapters2/lib/python3.11/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from dicl import dicl, adapters\n",
    "from dicl.icl import iclearner as icl\n",
    "from dicl.utils import data_readers\n",
    "\n",
    "from momentfm import MOMENTPipeline\n",
    "\n",
    "import importlib\n",
    "\n",
    "importlib.reload(dicl)\n",
    "importlib.reload(adapters)\n",
    "importlib.reload(icl)\n",
    "importlib.reload(data_readers)\n",
    "\n",
    "os.environ[\"HF_HOME\"] = \"/mnt/vdb/hugguingface/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DICL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/vdb/abenechehab/conda_envs/adapters2/lib/python3.11/site-packages/momentfm/models/moment.py:174: UserWarning: Only reconstruction head is pre-trained. Classification and forecasting heads must be fine-tuned.\n",
      "  warnings.warn(\"Only reconstruction head is pre-trained. Classification and forecasting heads must be fine-tuned.\")\n",
      "/mnt/vdb/abenechehab/conda_envs/adapters2/lib/python3.11/site-packages/momentfm/models/moment.py:174: UserWarning: Only reconstruction head is pre-trained. Classification and forecasting heads must be fine-tuned.\n",
      "  warnings.warn(\"Only reconstruction head is pre-trained. Classification and forecasting heads must be fine-tuned.\")\n",
      "/mnt/vdb/abenechehab/conda_envs/adapters2/lib/python3.11/site-packages/momentfm/models/moment.py:174: UserWarning: Only reconstruction head is pre-trained. Classification and forecasting heads must be fine-tuned.\n",
      "  warnings.warn(\"Only reconstruction head is pre-trained. Classification and forecasting heads must be fine-tuned.\")\n",
      "/mnt/vdb/abenechehab/conda_envs/adapters2/lib/python3.11/site-packages/momentfm/models/moment.py:174: UserWarning: Only reconstruction head is pre-trained. Classification and forecasting heads must be fine-tuned.\n",
      "  warnings.warn(\"Only reconstruction head is pre-trained. Classification and forecasting heads must be fine-tuned.\")\n",
      "/mnt/vdb/abenechehab/conda_envs/adapters2/lib/python3.11/site-packages/momentfm/models/moment.py:174: UserWarning: Only reconstruction head is pre-trained. Classification and forecasting heads must be fine-tuned.\n",
      "  warnings.warn(\"Only reconstruction head is pre-trained. Classification and forecasting heads must be fine-tuned.\")\n",
      "/mnt/vdb/abenechehab/conda_envs/adapters2/lib/python3.11/site-packages/momentfm/models/moment.py:174: UserWarning: Only reconstruction head is pre-trained. Classification and forecasting heads must be fine-tuned.\n",
      "  warnings.warn(\"Only reconstruction head is pre-trained. Classification and forecasting heads must be fine-tuned.\")\n",
      "/mnt/vdb/abenechehab/conda_envs/adapters2/lib/python3.11/site-packages/momentfm/models/moment.py:174: UserWarning: Only reconstruction head is pre-trained. Classification and forecasting heads must be fine-tuned.\n",
      "  warnings.warn(\"Only reconstruction head is pre-trained. Classification and forecasting heads must be fine-tuned.\")\n"
     ]
    }
   ],
   "source": [
    "is_fine_tuned = False\n",
    "forecast_horizon = 96\n",
    "model_name = \"AutonLab/MOMENT-1-large\"\n",
    "context_length = 512\n",
    "\n",
    "dataset_name = f\"ETTh1_pred={forecast_horizon}\"\n",
    "time_series, X_train, y_train, X_test, y_test, n_features = prepare_data(\n",
    "    dataset_name, context_length\n",
    ")\n",
    "\n",
    "base_projector = \"pca\"\n",
    "\n",
    "start = n_features if not base_projector else 1\n",
    "end = n_features + 1\n",
    "\n",
    "data_path = Path(\"/mnt/vdb/abenechehab/dicl-adapters/results/data.csv\")\n",
    "\n",
    "for n_components in range(start, end):\n",
    "    start_time = time.time()\n",
    "    model = load_moment_model(model_name, forecast_horizon)\n",
    "\n",
    "    disentangler = adapters.MultichannelProjector(\n",
    "        num_channels=n_features,\n",
    "        new_num_channels=n_components,\n",
    "        patch_window_size=None,\n",
    "        base_projector=base_projector,\n",
    "    )\n",
    "\n",
    "    iclearner = icl.MomentICLTrainer(\n",
    "        model=model, n_features=n_components, forecast_horizon=forecast_horizon\n",
    "    )\n",
    "\n",
    "    DICL = dicl.DICL(\n",
    "        disentangler=disentangler,\n",
    "        iclearner=iclearner,\n",
    "        n_features=n_features,\n",
    "        n_components=n_components,\n",
    "    )\n",
    "\n",
    "    DICL.fit_disentangler(X=X_train)\n",
    "\n",
    "    if is_fine_tuned:\n",
    "        DICL.fine_tune_iclearner(\n",
    "            X=X_train,\n",
    "            y=y_train,\n",
    "            n_epochs=1,\n",
    "            batch_size=8,\n",
    "            learning_rate=1e-4,\n",
    "            max_grad_norm=5.0,\n",
    "            verbose=1,\n",
    "            seed=13,\n",
    "        )\n",
    "\n",
    "    mean, mode, lb, ub = DICL.predict_multi_step(\n",
    "        X=time_series,\n",
    "        prediction_horizon=forecast_horizon,\n",
    "    )\n",
    "\n",
    "    metrics = DICL.compute_metrics()\n",
    "\n",
    "    save_metrics_to_csv(\n",
    "        metrics,\n",
    "        dataset_name,\n",
    "        model_name,\n",
    "        base_projector,\n",
    "        n_features,\n",
    "        n_components,\n",
    "        context_length,\n",
    "        forecast_horizon,\n",
    "        data_path,\n",
    "        is_fine_tuned=is_fine_tuned,\n",
    "        time=time.time() - start_time,\n",
    "    )\n",
    "\n",
    "    del DICL, disentangler, iclearner, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adapters2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
